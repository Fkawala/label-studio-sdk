{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import pre-annotations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have a data pipeline with models outputting predictions, you want to be able to import those predicted annotations, or pre-annotations, into Label Studio for review and correction. \n",
    "\n",
    "In this example, use the [Label Studio SDK](https://labelstud.io/sdk/index.html) to write a Python script that transforms and imports predictions into a Label Studio project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Label Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the Label Studio API using the Client module of the SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_studio_sdk import Client\n",
    "\n",
    "LABEL_STUDIO_URL = 'http://localhost:8081'\n",
    "API_KEY = '67cd883ccb099c9d476e7d7601cd9a6e5fdfe323'\n",
    "\n",
    "ls = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a project for your labels. In this example, create an [image classification](https://labelstud.io/templates/image_classification.html) project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = ls.start_project(\n",
    "    title='Project Created from SDK: Image Preannotation',\n",
    "    label_config='''\n",
    "    <View>\n",
    "    <Image name=\"image\" value=\"$image\"/>\n",
    "    <Choices name=\"image_class\" toName=\"image\">\n",
    "        <Choice value=\"Cat\"/>\n",
    "        <Choice value=\"Dog\"/>\n",
    "    </Choices>\n",
    "    </View>\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import tasks with pre-annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can import tasks with pre-annotations in several different ways. Choose one of these three methods for your script, based on how your model predictions are formatted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import tasks in Label Studio JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can format tasks in basic [JSON Label Studio format](https://labelstud.io/guide/tasks.html#Basic-Label-Studio-JSON-format) and choose to import the pre-annotations that way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36, 37]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.import_tasks(\n",
    "    [{\n",
    "        'data': {'image': 'https://data.heartex.net/open-images/train_0/mini/0045dd96bf73936c.jpg'},\n",
    "        'predictions': [{\n",
    "            'result': [{\n",
    "                'from_name': 'image_class',\n",
    "                'to_name': 'image',\n",
    "                'type': 'choices',\n",
    "                'value': {\n",
    "                    'choices': ['Dog']\n",
    "                }\n",
    "            }],\n",
    "            'score': 0.87\n",
    "        }]\n",
    "    }, {\n",
    "        'data': {'image': 'https://data.heartex.net/open-images/train_0/mini/0083d02f6ad18b38.jpg'},\n",
    "        'predictions': [{\n",
    "            'result': [{\n",
    "                'from_name': 'image_class',\n",
    "                'to_name': 'image',\n",
    "                'type': 'choices',\n",
    "                'value': {\n",
    "                    'choices': ['Cat']\n",
    "                }\n",
    "            }],\n",
    "            'score': 0.65\n",
    "        }]\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you're not importing predictions for an image classification task, see the documentation for [importing pre-annotations](https://labelstud.io/guide/predictions.html) in Label Studio JSON format for more examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import simple JSON predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simpler JSON format is a way to import pre-annotation results from a specific field for a single image. In this case, import task data with predictions in the `pet` field, and specify that the `pet` field contains the predicted classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38, 39]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.import_tasks(\n",
    "    [{'image': f'https://data.heartex.net/open-images/train_0/mini/0045dd96bf73936c.jpg', 'pet': 'Dog'},\n",
    "    {'image': f'https://data.heartex.net/open-images/train_0/mini/0083d02f6ad18b38.jpg', 'pet': 'Cat'}],\n",
    "    preannotated_from_fields=['pet']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Import predictions from CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your predictions are stored in CSV files, you can use pandas to read the dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from pandas) (1.21.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>pet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://data.heartex.net/open-images/train_0/m...</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://data.heartex.net/open-images/train_0/m...</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  pet\n",
       "0  https://data.heartex.net/open-images/train_0/m...  Dog\n",
       "1  https://data.heartex.net/open-images/train_0/m...  Cat"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('data/images.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can specify the CSV file with the image references, and specify that the `pet` field contains the predicted classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 41]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.import_tasks('data/images.csv', preannotated_from_fields=['pet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Import predictions to existing tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, you may want to apply predictions to already imported tasks. For example, you can retrieve task from Label Studio, then create a new prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 52,\n",
       " 'model_version': '1',\n",
       " 'created_ago': '0\\xa0minutes',\n",
       " 'result': [{'from_name': 'image_class',\n",
       "   'to_name': 'image',\n",
       "   'type': 'choices',\n",
       "   'value': {'choices': ['Dog']}}],\n",
       " 'score': 0.0,\n",
       " 'cluster': None,\n",
       " 'neighbors': None,\n",
       " 'mislabeling': 0.0,\n",
       " 'created_at': '2021-11-15T20:44:06.902902Z',\n",
       " 'updated_at': '2021-11-15T20:44:06.902902Z',\n",
       " 'task': 36}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_ids = project.get_tasks_ids()\n",
    "project.create_prediction(tasks_ids[0], result='Dog', model_version='1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or bunch of predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created': 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [{\n",
    "    \"task\": tasks_ids[0],\n",
    "    \"result\": \"Dog\",\n",
    "    \"score\": 0.9\n",
    "}, {\n",
    "    \"task\": tasks_ids[1],\n",
    "    \"result\": \"Cat\",\n",
    "    \"score\": 0.8\n",
    "}]\n",
    "project.create_predictions(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In more complex annotation scenarios, check out [JSON format for expected predictions / preannotations](https://labelstud.io/guide/predictions.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate tasks in Label Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing pre-annotations using your preferred method, you can open Label Studio at http://localhost:8080 and correct and review the predictions and finish annotating your tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate prediction accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using Label Studio Enterprise, you can calculate the accuracy of your predictions compared to the corrected annotations created as a ground truth dataset. \n",
    "\n",
    "Install and import the [evalme package](https://github.com/heartexlabs/label-studio-evalme) and calculate an agreement score for each task, comparing the annotation to the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: label-studio-evalme in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (0.0.17)\n",
      "Requirement already satisfied: xmljson==0.2.0 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from label-studio-evalme) (0.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from label-studio-evalme) (21.2.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from label-studio-evalme) (1.4.1)\n",
      "Requirement already satisfied: textdistance==4.1.5 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from label-studio-evalme) (4.1.5)\n",
      "Requirement already satisfied: label-studio-converter==0.0.33rc5 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from label-studio-evalme) (0.0.33rc5)\n",
      "Requirement already satisfied: requests==2.25.1 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from label-studio-evalme) (2.25.1)\n",
      "Requirement already satisfied: attr==0.3.1 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from label-studio-evalme) (0.3.1)\n",
      "Requirement already satisfied: lxml>=4.2.5 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from label-studio-evalme) (4.6.4)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from label-studio-evalme) (1.21.4)\n",
      "Requirement already satisfied: Shapely==1.7.1 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from label-studio-evalme) (1.7.1)\n",
      "Requirement already satisfied: nltk==3.5 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from label-studio-converter==0.0.33rc5->label-studio-evalme) (3.5)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from label-studio-converter==0.0.33rc5->label-studio-evalme) (1.3.4)\n",
      "Requirement already satisfied: Pillow==8.3.2 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from label-studio-converter==0.0.33rc5->label-studio-evalme) (8.3.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from requests==2.25.1->label-studio-evalme) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from requests==2.25.1->label-studio-evalme) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from requests==2.25.1->label-studio-evalme) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from requests==2.25.1->label-studio-evalme) (1.26.7)\n",
      "Requirement already satisfied: click in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from nltk==3.5->label-studio-converter==0.0.33rc5->label-studio-evalme) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from nltk==3.5->label-studio-converter==0.0.33rc5->label-studio-evalme) (1.1.0)\n",
      "Requirement already satisfied: regex in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from nltk==3.5->label-studio-converter==0.0.33rc5->label-studio-evalme) (2021.11.10)\n",
      "Requirement already satisfied: tqdm in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from nltk==3.5->label-studio-converter==0.0.33rc5->label-studio-evalme) (4.62.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from pandas>=0.24.0->label-studio-converter==0.0.33rc5->label-studio-evalme) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from pandas>=0.24.0->label-studio-converter==0.0.33rc5->label-studio-evalme) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->label-studio-converter==0.0.33rc5->label-studio-evalme) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from click->nltk==3.5->label-studio-converter==0.0.33rc5->label-studio-evalme) (0.4.4)\n",
      "Requirement already satisfied: importlib-metadata in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from click->nltk==3.5->label-studio-converter==0.0.33rc5->label-studio-evalme) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from importlib-metadata->click->nltk==3.5->label-studio-converter==0.0.33rc5->label-studio-evalme) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\projects\\heartex\\label-studio-sdk\\venv\\lib\\site-packages (from importlib-metadata->click->nltk==3.5->label-studio-converter==0.0.33rc5->label-studio-evalme) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install label-studio-evalme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-annotation agreement scores:\n",
      "40 ==> 1.0\n",
      "41 ==> 0.0\n",
      "38 ==> 1.0\n",
      "39 ==> 1.0\n",
      "37 ==> 1.0\n",
      "36 ==> 1.0\n",
      "Pre-annotation accuracy:  83%\n"
     ]
    }
   ],
   "source": [
    "from evalme.metrics import get_agreement\n",
    "\n",
    "\n",
    "print('Pre-annotation agreement scores:')\n",
    "\n",
    "total_score = 0\n",
    "n = 0\n",
    "for task in project.get_project_tasks():\n",
    "    score = get_agreement(task['annotations'][0], task['predictions'][0])\n",
    "    print(f'{task[\"id\"]} ==> {score}')\n",
    "    total_score += score\n",
    "    n += 1\n",
    "\n",
    "print(f'Pre-annotation accuracy: {100 * total_score / n: .0f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Label Studio SDK, you can more easily import pre-annotated tasks into Label Studio so that you can create ground truth datasets, visually review the accuracy of predictions, and more. \n",
    "\n",
    "The `preannotated_from_fields` option for the `import_tasks()` method makes it easier to add your predictions without worrying about the intricacies of the Label Studio JSON format, but you can still use that field to add valuable metadata such as prediction scores and model versions to your pre-annotated task data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}